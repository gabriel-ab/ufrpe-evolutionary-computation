{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_LENGTH = 0\n",
    "MAX_LENGTH = 8\n",
    "MIN_NEURONS = 2\n",
    "MAX_NEURONS = 8\n",
    "RANDOM_STATE = 42\n",
    "DATA_BASE_DIR = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m algorithms, base, creator, tools\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m randint\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deap'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dataclasses as dc\n",
    "import random\n",
    "import warnings\n",
    "from functools import cached_property, partial\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "from deap import algorithms, base, creator, tools\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm.contrib.concurrent import process_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_field(start: float, end: float):\n",
    "    def factory():\n",
    "        return start + random.random() * (end - start)\n",
    "\n",
    "    return dc.field(default_factory=factory)\n",
    "\n",
    "\n",
    "def list_field() -> list[int]:\n",
    "    def factory() -> list[int]:\n",
    "        return [\n",
    "            random.randint(MIN_NEURONS, MAX_NEURONS)\n",
    "            for _ in range(random.randint(MIN_LENGTH, MAX_LENGTH))\n",
    "        ]\n",
    "\n",
    "    return dc.field(default_factory=factory)\n",
    "\n",
    "\n",
    "def int_field(start: float, end: float):\n",
    "    return dc.field(default_factory=partial(random.randint, start, end))\n",
    "\n",
    "\n",
    "def str_field(*options: str) -> str:\n",
    "    return dc.field(default_factory=partial(random.choice, options))\n",
    "\n",
    "\n",
    "@dc.dataclass(slots=True)\n",
    "class Individual:\n",
    "    n_estimators: int = randint(10, 200)\n",
    "    max_depth: int = randint(1, 20)\n",
    "    min_samples_split: int = randint(2, 20)\n",
    "    min_samples_leaf: int = randint(1, 20)\n",
    "    bootstrap: bool = [True, False]\n",
    "    criterion: str = [\"gini\", \"entropy\"]\n",
    "\n",
    "    @cached_property\n",
    "    def model(self):\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=randint(10, 200),\n",
    "            max_depth=randint(1, 20),\n",
    "            min_samples_split=randint(2, 20),\n",
    "            min_samples_leaf=randint(1, 20),\n",
    "            bootstrap=[True, False],\n",
    "            criterion=[\"gini\", \"entropy\"],\n",
    "        )\n",
    "\n",
    "    def mutate(self, indpb: float = 0.2):\n",
    "        \"Take one field and re-generate i'ts value\"\n",
    "        fields = dc.fields(self)\n",
    "        if random.random() < indpb:\n",
    "            field = random.choice(fields)\n",
    "            setattr(self, field.name, field.default_factory())\n",
    "        return self\n",
    "\n",
    "    def mate_onepoint(self, other):\n",
    "        field_names = [field.name for field in dc.fields(self)]\n",
    "        point = random.randint(0, len(field_names))\n",
    "        child1 = type(self)(\n",
    "            **{\n",
    "                attr: getattr(self if i < point else other, attr)\n",
    "                for i, attr in enumerate(field_names)\n",
    "            }\n",
    "        )\n",
    "        child2 = type(self)(\n",
    "            **{\n",
    "                attr: getattr(other if i < point else self, attr)\n",
    "                for i, attr in enumerate(field_names)\n",
    "            }\n",
    "        )\n",
    "        return child1, child2\n",
    "\n",
    "    def mate_oneattr(self, other):\n",
    "        field_names = [field.name for field in dc.fields(self)]\n",
    "        point = random.randint(0, len(field_names))\n",
    "        child1 = type(self)(\n",
    "            **{\n",
    "                attr: getattr(self if i == point else other, attr)\n",
    "                for i, attr in enumerate(field_names)\n",
    "            }\n",
    "        )\n",
    "        child2 = type(self)(\n",
    "            **{\n",
    "                attr: getattr(other if i == point else self, attr)\n",
    "                for i, attr in enumerate(field_names)\n",
    "            }\n",
    "        )\n",
    "        return child1, child2\n",
    "\n",
    "    def evaluate(self, x_train, x_test, y_train, y_test):\n",
    "        with warnings.catch_warnings(action=\"ignore\"):\n",
    "            ypred = self.model.fit(x_train, y_train).predict(x_test)\n",
    "        report = classification_report(y_test, ypred, output_dict=True)\n",
    "        return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0, -1.0))\n",
    "creator.create(\"Individual\", Individual, fitness=creator.FitnessMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(ngen: int, population: int, halloffame: int = 5):\n",
    "    print(\"Carregando Dataset\")\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    X_train = pd.read_csv(os.path.join(DATA_BASE_DIR, \"X_train.csv\"))\n",
    "    X_test = pd.read_csv(os.path.join(DATA_BASE_DIR, \"X_test.csv\"))\n",
    "    y_train = pd.read_csv(os.path.join(DATA_BASE_DIR, \"y_train.csv\"))\n",
    "    y_test = pd.read_csv(os.path.join(DATA_BASE_DIR, \"y_test.csv\"))\n",
    "\n",
    "    X_train_encoded = np.array(\n",
    "        [nlp(x[\"input\"]).vector for _, x in X_train.iterrows()], dtype=np.float32\n",
    "    )\n",
    "    X_test_encoded = np.array(\n",
    "        [nlp(x[\"input\"]).vector for _, x in X_test.iterrows()], dtype=np.float32\n",
    "    )\n",
    "\n",
    "    evaluate = partial(\n",
    "        Individual.evaluate,\n",
    "        x_train=X_train_encoded,\n",
    "        x_test=X_test_encoded,\n",
    "        y_train=y_train,\n",
    "        y_test=y_test,\n",
    "    )\n",
    "\n",
    "    print(\"Construindo Toolbox\")\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"individual\", creator.Individual)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    toolbox.register(\"mate\", tools.cxMessyOnePoint)\n",
    "    toolbox.register(\n",
    "        \"mutate\", tools.mutUniformInt, low=MIN_NEURONS, up=MAX_NEURONS, indpb=0.2\n",
    "    )\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=5)\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "    toolbox.register(\"map\", process_map, max_workers=6, chunksize=8, ncols=80)\n",
    "\n",
    "    pop = toolbox.population(n=population)\n",
    "    hof = tools.HallOfFame(halloffame)\n",
    "    stats = tools.Statistics()\n",
    "    stats.register(\"min\", lambda pop: min(ind.fitness.values for ind in pop))\n",
    "\n",
    "    print(\"Iniciando Algoritmo\")\n",
    "    pop, log = algorithms.eaSimple(\n",
    "        pop, toolbox, 0.2, 0.2, ngen=ngen, halloffame=hof, stats=stats\n",
    "    )\n",
    "    print(log)\n",
    "    for ind in hof:\n",
    "        report = ind.fitness.values\n",
    "        print(\"Error: %s, Size: %s\" % (report[\"accuracy\"]))\n",
    "    print(\n",
    "        \"Best model parameters: %s - accuracy: %f\" % (hof[0], hof[0].fitness.values[0])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(ngen=48, population=24)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ufrpe-ce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
